File f_feats_train = csv_file("../../data/fm_train_mnist_16x16.dat")
File f_feats_test = csv_file("../../data/fm_test_mnist_16x16.dat")
File f_labels_train = csv_file("../../data/labels_train_mnist_16x16.dat")
File f_labels_test = csv_file("../../data/labels_test_mnist_16x16.dat")

Math:init_random(10)

#![create_features]
Features features_train = features(f_feats_train)
Features features_test = features(f_feats_test)
Labels labels_train = labels(f_labels_train)
Labels labels_test = labels(f_labels_test)
#![create_features]

#![create_instance]
Machine network = machine("NeuralNetwork", labels=labels_train, max_num_epochs=4, epsilon=0.0, optimization_method=enum ENNOptimizationMethod.NNOM_GRADIENT_DESCENT, gd_learning_rate=0.01, gd_mini_batch_size=3, max_norm=1.0, dropout_input=0.5)
#![create_instance]

#![add_layers]
int num_feats = features_train.get_int("num_features")
DynamicObjectArray layers_conv()
NeuralLayer input = neural_layer("NeuralInputLayer", width=16, height=16,num_neurons=256) 
network.add("layers", input)
NeuralLayer conv1 = neural_layer("NeuralConvolutionalLayer", num_maps=10, radius_x=2, radius_y=2, pooling_width=2, pooling_height=2, stride_x=1, stride_y=1)
network.add("layers", conv1)
NeuralLayer conv2 = neural_layer("NeuralConvolutionalLayer", num_maps=15, radius_x=2, radius_y=2, pooling_width=2, pooling_height=2, stride_x=1, stride_y=1)
network.add("layers", conv2)
NeuralLayer softmax = neural_layer("NeuralSoftmaxLayer", num_neurons=10)
network.add("layers", softmax)
#![add_layers]

#![train_and_apply]
network.train(features_train)
Labels labels_predict = network.apply(features_train)
#![train_and_apply]

#![evaluate_accuracy]
Evaluation eval = evaluation("MulticlassAccuracy")
real accuracy = eval.evaluate(labels_predict, labels_train)
#![evaluate_accuracy]

# additional integration testing variables
RealVector output = labels_predict.get_real_vector("labels")
