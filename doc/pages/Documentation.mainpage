/** \mainpage SHOGUN Project Documentation

  \image html shogun_logo.png

  \section intro_sec Introduction
The Shogun Machine learning toolbox provides a wide range of *unified* and *efficient* Machine Learning (ML) methods. The toolbox seamlessly allows to easily combine multiple data representations, algorithm classes, and general purpose tools. This enables both rapid prototyping of data pipelines and extensibility in terms of new algorithms. We combine modern software architecture in C++ with both efficient low-level computing backends and cutting edge algorithm implementations to solve large-scale Machine Learning problems (yet) on single machines.

One of Shogun's most exciting features is that you can use the toolbox through a *unified* interface from C++, Python, Octave, R, Java, Lua, C#, etc. This not just means that we are independent of trends in computing languages, but it also lets you use Shogun as a vehicle to expose your algorithm to multiple communities. We use [SWIG](http://www.swig.org/) to enable *bidirectional* communication between C++ and target languages. Shogun runs under Linux/Unix, MacOS, Windows.

Originally focussing on large-scale kernel methods and bioinformatics (for a list of scientific papers mentioning Shogun, see [here](http://scholar.google.com/scholar?hl=en&q=shogun+toolbox), the toolbox saw massive extensions to other fields in recent years. It now offers features that span the whole space of Machine Learning methods, including many classical methods in classification, regression, dimensionality reduction, clustering, but also more advanced algorithm classes such as metric, multi-task, structured output, and online learning, as well as feature hashing, ensemble methods, and optimization, just to name a few. Shogun in addition contains a number of exclusive state-of-the art algorithms such as a wealth of efficient SVM implementations, Multiple Kernel Learning, kernel hypothesis testing, Krylov methods, etc. All algorithms are supported by a collection of general purpose methods for evaluation, parameter tuning, preprocessing, serialisation & I/O, etc; the resulting combinatorial possibilities are huge. See our [feature list](http://www.shogun-toolbox.org/page/features/) for more details.

The wealth of ML open-source software allows us to offer bindings to other sophisticated libraries including: [LibSVM](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)/[LibLinear](http://www.csie.ntu.edu.tw/~cjlin/liblinear/), [SVMLight](http://svmlight.joachims.org/), [LibOCAS](http://cmp.felk.cvut.cz/~xfrancv/ocas/html/), [libqp](http://cmp.felk.cvut.cz/~xfrancv/libqp/html/), [VowpalWabbit](http://www.hunch.net/~vw/), [Tapkee](http://tapkee.lisitsyn.me/), [SLEP](http://www.public.asu.edu/~jye02/Software/SLEP/), [GPML](http://www.gaussianprocess.org/gpml/code/matlab/doc/) and more. See our [list of integrated external libraries](http://www.shogun-toolbox.org/page/about/contributions).

Shogun got initiated in 1999 by [Soeren Sonnenburg](http://sonnenburgs.de/soeren) and [Gunnar Raetsch](http://www.raetschlab.org/) (that's where the name ShoGun originates from). It is now developed by a much larger Team cf. [website](http://shogun-toolbox.org/page/about/ourteam) and [AUTHORS](http://www.github.com/shogun-toolbox/shogun/wiki/AUTHORS), and would not have been possible without the patches and bug reports by various people. See [CONTRIBUTIONS](http://www.github.com/shogun-toolbox/shogun/wiki/CONTRIBUTIONS) for a detailed list. Statistics on Shogun's development activity can be found on [ohloh](https://www.openhub.net/p/shogun).

  \li \subpage installation
  \li \subpage screenshots
  \li \subpage tutorial
  \li \subpage examples
  \li \subpage methods "Implemented Methods"
  \li \subpage interfaces
  \li \subpage faq
  \li \subpage developer "Developer Guide"
  \li \subpage authors
  \li \subpage license

  Sincerely,
  the shogun-authors.
*/
