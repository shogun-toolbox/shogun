{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Clustering with KMeans in Shogun Machine Learning Toolbox"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Notebook by Parijat Mazumdar (GitHub ID: <a href='https://github.com/mazumdarparijat'>mazumdarparijat</a>)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we are going to see how Shogun Machine Learning Toolbox can be used for clustering with KMeans. In particular, we will be discussing the various options/choices provided to a user by the KMeans implementation in Shogun. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KMeans - An Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The KMeans clustering algorithm is used to partition a space of n observations into k partitions (or clusters). Each of these clusters is denoted by the mean of the observation vectors belonging to it and a unique label which is attached to all the observations belonging to it. Thus, in general, the algorithm takes parameter k and an observation matrix (along with the notion of distance between points ie <i>distance metric</i>) as input and returns mean of each of the k clusters along with labels indicating belongingness of each obsevations. Let us construct a simple example to understand how it is done in Shogun. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us start by creating a toy dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "\n",
      "rectangle = numpy.array([[0.,0.,2.,2.],[0.,100.,0.,100.]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The toy data created above consists of 4 points forming a rectangle. Lets plot it for convenience."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as pyplot\n",
      "\n",
      "figure,axis = pyplot.subplots(1,1)\n",
      "axis.plot(rectangle[0], rectangle[1], 'o', color='red', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('Toy data : Rectangle')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With data at our disposal, it is time to apply KMeans to it using the KMeans class in Shogun. First we construct Shogun features from our data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import *\n",
      "\n",
      "train_features = RealFeatures(rectangle)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we specify the number of clusters we want and create a distance object specifying the distance metric to be used over our data for our KMeans training:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# number of clusters\n",
      "k = 2\n",
      "\n",
      "# distance metric over feature matrix - Euclidean distance\n",
      "distance = EuclideanDistance(train_features, train_features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we create a KMeans object with our desired inputs/parameters and train:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KMeans object created\n",
      "kmeans = KMeans(k, distance)\n",
      "\n",
      "# KMeans training \n",
      "kmeans.train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that training has been done, lets get the cluster centers and label for each data point "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cluster centers\n",
      "centers = kmeans.get_cluster_centers()\n",
      "\n",
      "# Labels for data points\n",
      "result = kmeans.apply()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally let us plot the centers and the data points (in different colours for different clusters):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure,axis = pyplot.subplots(1,1)\n",
      "for i in xrange(4):\n",
      "    if (result[i]==0.0):\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='green', markersize=5)\n",
      "    else:\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='blue', markersize=5)\n",
      "    axis.plot(centers[0,0], centers[1,0], 'x', color='green', markersize=10)\n",
      "    axis.plot(centers[0,1], centers[1,1], 'x', color='blue', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('KMeans Results')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the we have already worked out a simple KMeans implementation, its time to understand certain specifics of KMeans implementaion and the options provided by Shogun to its users."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Initialization of cluster centers "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The KMeans algorithm requires that the cluster centers be initialized with some values. Shogun offers 3 ways to initialize the clusters. <ul><li>Random initialization (default)</li><li>Initialization by hand</li><li>Initialization using KMeans++ algorithm</li></ul>Unless the user supplies initial centers or tells Shogun to use KMeans++, Random initialization is the default method used for cluster center initialization. This was precisely the case in the example discussed above."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "    Initialization by hand"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are 2 ways to initialize centers by hand. One way is to pass on the centers during KMeans object creation, as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial_centers = numpy.array([[0.,2.],[50.,50.]])\n",
      "\n",
      "# initial centers passed\n",
      "kmeans = KMeans(k, distance, initial_centers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, lets first get results by repeating the rest of the steps:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KMeans training \n",
      "kmeans.train(train_features)\n",
      "\n",
      "# cluster centers\n",
      "centers = kmeans.get_cluster_centers()\n",
      "\n",
      "# Labels for data points\n",
      "result = kmeans.apply()\n",
      "\n",
      "figure,axis = pyplot.subplots(1,1)\n",
      "for i in xrange(4):\n",
      "    if (result[i]==0.0):\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='green', markersize=5)\n",
      "    else:\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='blue', markersize=5)\n",
      "    axis.plot(centers[0,0], centers[1,0], 'x', color='green', markersize=10)\n",
      "    axis.plot(centers[0,1], centers[1,1], 'x', color='blue', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('Hand initialized KMeans Results 1')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the result obtained above is as expected because the chosen initial centers are a local minima for the KMeans optimization algorithm. The other way to initial centers by hand is as follows: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_initial_centers = numpy.array([[1.,0.],[1.,100.]])\n",
      "\n",
      "# set new initial centers\n",
      "kmeans.set_initial_centers(new_initial_centers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets complete the rest of the code to get results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KMeans training \n",
      "kmeans.train(train_features)\n",
      "\n",
      "# cluster centers\n",
      "centers = kmeans.get_cluster_centers()\n",
      "\n",
      "# Labels for data points\n",
      "result = kmeans.apply()\n",
      "\n",
      "figure,axis = pyplot.subplots(1,1)\n",
      "for i in xrange(4):\n",
      "    if (result[i]==0.0):\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='green', markersize=5)\n",
      "    else:\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='blue', markersize=5)\n",
      "    axis.plot(centers[0,0], centers[1,0], 'x', color='green', markersize=10)\n",
      "    axis.plot(centers[0,1], centers[1,1], 'x', color='blue', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('Hand initialized KMeans Results 2')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Initializing using KMeans++ algorithm"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In Shogun, a user can also use KMeans++ algorithm for center initialization. Using KMeans++ for center initialization is beneficial because it reduces total iterations used by KMeans and also the final centers mostly correspond to the global minima, which is often not the case with KMeans with random initialization. One of the ways to use KMeans++ is to set flag as <i>true</i> during KMeans object creation, as follows:  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set flag for using KMeans++\n",
      "kmeans = KMeans(k, distance, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The other way to initilize using KMeans++ is as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set KMeans++ flag\n",
      "kmeans.set_use_kmeanspp(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Completing the rest steps to get result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KMeans training \n",
      "kmeans.train(train_features)\n",
      "\n",
      "# cluster centers\n",
      "centers = kmeans.get_cluster_centers()\n",
      "\n",
      "# Labels for data points\n",
      "result = kmeans.apply()\n",
      "\n",
      "figure,axis = pyplot.subplots(1,1)\n",
      "for i in xrange(4):\n",
      "    if (result[i]==0.0):\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='green', markersize=5)\n",
      "    else:\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='blue', markersize=5)\n",
      "    axis.plot(centers[0,0], centers[1,0], 'x', color='green', markersize=10)\n",
      "    axis.plot(centers[0,1], centers[1,1], 'x', color='blue', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('KMeans with KMeans++ Results')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To switch back to random initialization, you may use:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#unset KMeans++ flag\n",
      "kmeans.set_use_kmeanspp(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training Methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Shogun offers 2 training methods for KMeans clustering:<ul><li>Classical Lloyd's training (default)</li><li>mini-batch KMeans training</li><ul>Lloyd's training method is used by Shogun by default unless user switches to mini-batch training method."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Mini-Batch KMeans"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mini-batch KMeans is very useful in case of extremely large datasets and/or very high dimensional data which is often the case in text mining. One can switch to Mini-batch KMeans training while creating KMeans object as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set training method to mini-batch\n",
      "kmeans = KMeans(k, distance, KMM_MINI_BATCH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One can switch to Mini-batch KMeans also by making use of the following method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set training method to mini-batch\n",
      "kmeans.set_train_method(KMM_MINI_BATCH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In mini-batch KMeans it is important to set batch-size as well as number of iterations. It can be done in the following ways:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set parameters together. batch size-2 no. of iterations-100\n",
      "kmeans.set_mbKMeans_params(2, 100)\n",
      "\n",
      "# OR\n",
      "\n",
      "# set batch size\n",
      "kmeans.set_mbKMeans_batch_size(2)\n",
      "\n",
      "# set no. of iterations\n",
      "kmeans.set_mbKMeans_iter(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Completing the code to get results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# KMeans training \n",
      "kmeans.train(train_features)\n",
      "\n",
      "# cluster centers\n",
      "centers = kmeans.get_cluster_centers()\n",
      "\n",
      "# Labels for data points\n",
      "result = kmeans.apply()\n",
      "\n",
      "figure,axis = pyplot.subplots(1,1)\n",
      "for i in xrange(4):\n",
      "    if (result[i]==0.0):\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='green', markersize=5)\n",
      "    else:\n",
      "        axis.plot(rectangle[0,i], rectangle[1,i], 'o', color='blue', markersize=5)\n",
      "    axis.plot(centers[0,0], centers[1,0], 'x', color='green', markersize=10)\n",
      "    axis.plot(centers[0,1], centers[1,1], 'x', color='blue', markersize=10)\n",
      "axis.set_xlim(-3,3)\n",
      "axis.set_ylim(-20,150)\n",
      "axis.set_title('Mini-batch KMeans Results')\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One can switch back to Lloyd's KMeans in the following way:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set training method to mini-batch\n",
      "kmeans.set_train_method(KMM_LLOYD)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    }
   ],
   "metadata": {}
  }
 ]
}
