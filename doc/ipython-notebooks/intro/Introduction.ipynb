{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Shogun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Saurabh Mahindre - <a href=\"https://github.com/Saurabh7\">github.com/Saurabh7</a> as a part of <a href=\"http://www.google-melange.com/gsoc/project/details/google/gsoc2014/saurabh7/5750085036015616\">Google Summer of Code 2014 project</a> mentored by - Heiko Strathmann - <a href=\"https://github.com/karlnapf\">github.com/karlnapf</a> - <a href=\"http://herrstrathmann.de/\">herrstrathmann.de</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will see how machine learning problems are generally represented and solved in Shogun. As a primer to Shogun's many capabilities, we will see how various types of data and its attributes are handled and also how prediction is done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Introduction](#Introduction)\n",
    "2. [Using datasets](#Using-datasets)\n",
    "3. [Feature representations](#Feature-representations)\n",
    "4. [Labels](#Assigning-labels)\n",
    "5. [Preprocessing data](#Preprocessing-data)\n",
    "6. [Supervised Learning with Shogun's Machine interface](#supervised)\n",
    "7. [Evaluating performance and Model selection](#Evaluating-performance-and-Model-selection)\n",
    "8. [Example: Regression](#More-predictions:-Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning concerns the construction and study of systems that can learn from data via exploiting certain types of structure within these. The uncovered patterns are then used to predict future data, or to perform other kinds of decision making. Two main classes (among others) of Machine Learning algorithms are: predictive or [supervised](http://en.wikipedia.org/wiki/Supervised_learning) learning and descriptive or [Unsupervised](http://en.wikipedia.org/wiki/Unsupervised_learning) learning. Shogun provides functionality to address those (and more) problem classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SHOGUN_DATA_DIR=os.getenv('SHOGUN_DATA_DIR', '../../../data')\n",
    "import shogun as sg\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a general problem setting for the supervised learning approach, the goal is to learn a mapping from inputs $x_i\\in\\mathcal{X} $ to outputs $y_i \\in \\mathcal{Y}$, given a labeled set of input-output pairs $ \\mathcal{D} = {(x_i,y_i)}^{\\text N}_{i=1} $$\\subseteq \\mathcal{X} \\times \\mathcal{Y}$. Here $ \\mathcal{D}$ is called the training set, and $\\text N$ is the number of training examples. In the simplest setting, each training input $x_i$ is a  $\\mathcal{D}$ -dimensional vector of numbers, representing, say, the height and weight of a person. These are called $\\textbf {features}$, attributes or covariates. In general, however, $x_i$ could be a complex structured object, such as an image.<ul><li>When the response variable $y_i$ is categorical and discrete, $y_i \\in$ {1,...,C} (say male or female) it is a [classification](http://en.wikipedia.org/wiki/Classification_in_machine_learning) problem.</li><li>When it is continuous (say the prices of houses) it is a [regression](http://en.wikipedia.org/wiki/Regression_analysis) problem.</li></ul>\n",
    "For the unsupervised learning\n",
    "approach we are only given inputs,  $\\mathcal{D} = {(x_i)}^{\\text N}_{i=1}$ , and the goal is to find “interesting\n",
    "patterns” in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider an example, we have a dataset about various attributes of individuals and we know whether or not they are diabetic. The data reveals certain configurations of attributes that correspond to diabetic patients and others that correspond to non-diabetic patients. When given a set of attributes for a new patient, the goal is to predict whether the patient is diabetic or not. This type of learning problem falls under [Supervised learning](http://en.wikipedia.org/wiki/Supervised_learning), in particular, [classification](http://en.wikipedia.org/wiki/Classification_in_machine_learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shogun provides the capability to load datasets of different formats using [File](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1File.html).</br>  A real world dataset: [Pima Indians Diabetes data set](http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) is used now. We load the `LibSVM` format file using Shogun's [LibSVMFile](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CLibSVMFile.html) class. The `LibSVM` format is: $$\\space \\text {label}\\space \\text{attribute1:value1 attribute2:value2 }...$$$$\\space.$$$$\\space .$$ LibSVM uses the so called \"sparse\" format where zero values do not need to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the file\n",
    "data_file=sg.read_libsvm(os.path.join(SHOGUN_DATA_DIR, 'uci/diabetes/diabetes_scale.svm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a [LibSVMFile](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CLibSVMFile.html) object which we will later use to access the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get off the mark, let us see how Shogun handles the attributes of the data using [Features](http://shogun-toolbox.org/api/latest/classshogun_1_1Features.html) class. Shogun supports wide range of feature representations. We believe it is a good idea to have different forms of data, rather than converting them all into matrices. Among these are: $\\hspace {20mm}$<ul><li>[String features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CStringFeatures.html): Implements a list of strings. Not limited to character strings, but could also be sequences of floating point numbers etc. Have varying dimensions. </li> <li>[Dense features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1DenseFeatures.html): Implements dense feature matrices</li> <li>[Sparse features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1SparseFeatures.html):  Implements sparse matrices.</li><li>[Streaming features](http://shogun-toolbox.org/doc/en/latest/classshogun_1_1StreamingFeatures.html): For algorithms working on data streams (which are too large to fit into memory) </li></ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SpareRealFeatures` (sparse features handling `64 bit float` type data) are used to get the data from the file. Since `LibSVM` format files have labels included in the file, `load_with_labels` method of `SpareRealFeatures` is used. In this case it is interesting to play with two attributes, Plasma glucose concentration and Body Mass Index (BMI) and try to learn something about their relationship with the disease. We get hold of the feature matrix using `get_full_feature_matrix` and row vectors 1 and 5 are extracted. These are the attributes we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=sg.SparseRealFeatures()\n",
    "trainlab=f.load_with_labels(data_file)\n",
    "mat=f.get_full_feature_matrix()\n",
    "\n",
    "#exatract 2 attributes\n",
    "glucose_conc=mat[1]\n",
    "BMI=mat[5]\n",
    "\n",
    "#generate a numpy array\n",
    "feats=np.vstack((glucose_conc, BMI))\n",
    "print(feats, feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy, this is a matrix of 2 row-vectors of dimension 768. However, in Shogun, this will be a matrix of 768 column vectors of dimension 2. This is beacuse each data sample is stored in a column-major fashion, meaning each column here corresponds to an individual sample and each row in it to an atribute like BMI, Glucose concentration etc. To convert the extracted matrix into Shogun format, `RealFeatures` are used which are nothing but the above mentioned [Dense features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1DenseFeatures.html) of `64bit Float` type. To do this call the factory method, `features` with the  matrix (this should be a 64bit 2D numpy array) as the argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to shogun format\n",
    "feats_train = sg.create_features(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the general methods you might find useful are:\n",
    "\n",
    "* `get(\"feature_matrix\")`: The feature matrix can be accessed using this.\n",
    "* `get(\"num_features\")`: The total number of attributes can be accesed using this.\n",
    "* `get_num_vectors()`: To get total number of samples in data.\n",
    "* `feat_matrix[:,idx]`: To get all the attribute values (A.K.A [feature vector](http://en.wikipedia.org/wiki/Feature_vector)) for a particular sample by passing the index of the sample as argument.</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of features(attributes of data) and num of vectors(samples)\n",
    "feat_matrix=feats_train.get(\"feature_matrix\")\n",
    "num_f=feats_train.get(\"num_features\")\n",
    "num_s=feats_train.get_num_vectors()\n",
    "\n",
    "print('Number of attributes: %s and number of samples: %s' %(num_f, num_s))\n",
    "print('Number of rows of feature matrix: %s and number of columns: %s' %(feat_matrix.shape[0], feat_matrix.shape[1]))\n",
    "print('First column of feature matrix (Data for first individual):')\n",
    "print(feat_matrix[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning problems, training data is labelled. Shogun provides various types of labels to do this through [Clabels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1Labels.html). Some of these are:<ul><li>[Binary labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1BinaryLabels.html): Binary Labels for binary classification which can have values +1 or -1.</li><li>[Multiclass labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1MulticlassLabels.html): Multiclass Labels for multi-class classification which can have values from 0 to (num. of classes-1).</li><li>[Regression labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1RegressionLabels.html):  Real-valued labels used for regression problems and are returned as output of classifiers.</li><li>[Structured labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1StructuredLabels.html): Class of the labels used in Structured Output (SO) problems</li></ul></br> In this particular problem, our data can be of two types: diabetic or non-diabetic, so we need [binary labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1BinaryLabels.html). This makes it a [Binary Classification problem](http://en.wikipedia.org/wiki/Binary_classification), where the data has to be classified in two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to shogun format labels\n",
    "labels=sg.create_labels(trainlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels can be accessed using `get_labels` and the confidence vector using `get_values`. The total number of labels is available using `get_num_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=labels.get_num_labels()\n",
    "print('Number of labels:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually better to preprocess data to a standard form rather than handling it in raw form. The reasons are having a well behaved-scaling, many algorithms assume centered data, and that sometimes one wants to de-noise data (with say PCA). Preprocessors do not change the domain of the input features. It is possible to do various type of preprocessing using methods provided by [Preprocessor](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1Preprocessor.html) class. Some of these are:<ul><li>[Norm one](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CNormOne.html): Normalize vector to have norm 1.</li><li>[PruneVarSubMean](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CPruneVarSubMean.html):  Substract the mean and remove features that have zero variance. </li><li>[Dimension Reduction](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CDimensionReductionPreprocessor.html): Lower the dimensionality of given simple features.<ul><li>[PCA](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CPCA.html): Principal component analysis.</li><li>[Kernel PCA](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1KernelPCA.html): PCA using kernel methods.</li></ul></li></ul> The training data will now be preprocessed using [CPruneVarSubMean](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CPruneVarSubMean.html). This will basically remove data with zero variance and subtract the mean. Passing a `True` to the constructor makes the class normalise the varaince of the variables. It basically dividies every dimension through its standard-deviation. This is the reason behind removing dimensions with constant values.  It is required to initialize the preprocessor by passing the feature object to `init` before doing anything else. The raw and processed data is now plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc=sg.create_transformer(\"PruneVarSubMean\", divide_by_std=True)\n",
    "preproc.fit(feats_train)\n",
    "feats_train = preproc.transform(feats_train)\n",
    "# Store preprocessed feature matrix.\n",
    "preproc_data=feats_train.get(\"feature_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the raw training data.\n",
    "plt.figure(figsize=(13,6))\n",
    "pl1=plt.subplot(121)\n",
    "plt.gray()\n",
    "_=plt.scatter(feats[0, :], feats[1,:], c=labels.get(\"labels\"), s=50,\n",
    "              cmap=matplotlib.colors.ListedColormap([\"blue\", \"red\"]))\n",
    "plt.vlines(0, -1, 1, linestyle='solid', linewidths=2)\n",
    "plt.hlines(0, -1, 1, linestyle='solid', linewidths=2)\n",
    "plt.title(\"Raw Training Data\")\n",
    "_=plt.xlabel('Plasma glucose concentration')\n",
    "_=plt.ylabel('Body mass index')\n",
    "p1 = plt.Rectangle((0, 0), 1, 1, fc=\"r\")\n",
    "p2 = plt.Rectangle((0, 0), 1, 1, fc=\"b\")\n",
    "pl1.legend((p1, p2), [\"Non-diabetic\", \"Diabetic\"], loc=2)\n",
    "\n",
    "#Plot preprocessed data.\n",
    "pl2=plt.subplot(122)\n",
    "_=plt.scatter(preproc_data[0, :], preproc_data[1,:], c=labels.get(\"labels\"), s=50,\n",
    "              cmap=matplotlib.colors.ListedColormap([\"blue\", \"red\"]))\n",
    "plt.vlines(0, -5, 5, linestyle='solid', linewidths=2)\n",
    "plt.hlines(0, -5, 5, linestyle='solid', linewidths=2)\n",
    "plt.title(\"Training data after preprocessing\")\n",
    "_=plt.xlabel('Plasma glucose concentration')\n",
    "_=plt.ylabel('Body mass index')\n",
    "p1 = plt.Rectangle((0, 0), 1, 1, fc=\"r\")\n",
    "p2 = plt.Rectangle((0, 0), 1, 1, fc=\"b\")\n",
    "pl2.legend((p1, p2), [\"Non-diabetic\", \"Diabetic\"], loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal and vertical lines passing through zero are included to make the processing of data clear. Note that the now processed data has zero mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='supervised'>Supervised Learning with Shogun's <a href='http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1Machine.html'>Machine</a> interface</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Machine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1Machine.html) is Shogun's interface for general learning machines. Basically one has to ` train()`  the machine on some training data to be able to learn from it. Then we `apply()` it to test data to get predictions. Some of these are: <ul><li>[Kernel machine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1KernelMachine.html): Kernel based learning tools.</li><li>[Linear machine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1LinearMachine.html): Interface for all kinds of linear machines like classifiers.</li><li>[Distance machine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1DistanceMachine.html): A distance machine is based on a a-priori choosen distance.</li><li>[Gaussian process machine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1GaussianProcessMachine.html): A base class for Gaussian Processes. </li><li>And many more</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the prediction part, [Liblinear](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1LibLinear.html), a linear SVM is used to do the classification (more on SVMs in [this notebook](http://www.shogun-toolbox.org/static/notebook/current/SupportVectorMachines.html)). A linear SVM will find a linear separation with the largest possible margin. Here C is a penalty parameter on the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prameters to svm\n",
    "C=0.9\n",
    "\n",
    "svm=sg.create_machine(\"LibLinear\", C1=C, C2=C,\n",
    "               liblinear_solver_type=\"L2R_L2LOSS_SVC\")\n",
    "#train\n",
    "svm.train(feats_train, labels)\n",
    "\n",
    "size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now `apply` on test features to get predictions. For visualising the classification boundary, the whole XY is used as test data, i.e. we predict the class on every point in the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.linspace(-5.0, 5.0, size)\n",
    "x2=np.linspace(-5.0, 5.0, size)\n",
    "x, y=np.meshgrid(x1, x2)\n",
    "#Generate X-Y grid test data\n",
    "grid=sg.create_features(np.array((np.ravel(x), np.ravel(y))))\n",
    "\n",
    "#apply on test grid\n",
    "predictions = svm.apply(grid)\n",
    "#get output labels\n",
    "z=predictions.get_values().reshape((size, size))\n",
    "\n",
    "#plot\n",
    "plt.jet()\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.title(\"Classification\")\n",
    "c=plt.pcolor(x, y, z)\n",
    "_=plt.contour(x, y, z, linewidths=1, colors='black', hold=True)\n",
    "_=plt.colorbar(c)\n",
    "\n",
    "_=plt.scatter(preproc_data[0, :], preproc_data[1,:], c=trainlab, s=50,\n",
    "              cmap=matplotlib.colors.ListedColormap([\"blue\", \"red\"]))\n",
    "_=plt.xlabel('Plasma glucose concentration')\n",
    "_=plt.ylabel('Body mass index')\n",
    "plt.p1 = plt.Rectangle((0, 0), 1, 1, fc=\"r\")\n",
    "plt.p2 = plt.Rectangle((0, 0), 1, 1, fc=\"b\")\n",
    "plt.legend((p1, p2), [\"Non-diabetic\", \"Diabetic\"], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the weight vector of the separating hyperplane. It should tell us about the linear relationship between the features. The decision boundary is now plotted by solving for $\\bf{w}\\cdot\\bf{x}$ + $\\text{b}=0$. Here $\\text b$ is a bias term which allows the linear function to be offset from the origin of the used coordinate system. Methods `get_w()` and `get_bias()` are used to get the necessary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=svm.get(\"w\")\n",
    "b=svm.get(\"bias\")\n",
    "\n",
    "x1=np.linspace(-2.0, 3.0, 100)\n",
    "\n",
    "#solve for w.x+b=0\n",
    "def solve (x1):\n",
    "    return -( ( (w[0])*x1 + b )/w[1] )\n",
    "x2=list(map(solve, x1))\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(x1,x2, linewidth=2)\n",
    "plt.title(\"Decision boundary using w and bias\")\n",
    "_=plt.scatter(preproc_data[0, :], preproc_data[1,:], c=trainlab, s=50,\n",
    "              cmap=matplotlib.colors.ListedColormap([\"blue\", \"red\"]))\n",
    "_=plt.xlabel('Plasma glucose concentration')\n",
    "_=plt.ylabel('Body mass index')\n",
    "p1 = plt.Rectangle((0, 0), 1, 1, fc=\"r\")\n",
    "p2 = plt.Rectangle((0, 0), 1, 1, fc=\"b\")\n",
    "plt.legend((p1, p2), [\"Non-diabetic\", \"Diabetic\"], loc=2)\n",
    "\n",
    "print('w :', w)\n",
    "print('b :', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, a linear classifier does a reasonable job in distinguishing labelled data. An interpretation could be that individuals below a certain level of BMI and glucose are likely to have no Diabetes. \n",
    "For problems where the data cannot be separated linearly, there are more advanced classification methods, as for example all of Shogun's [kernel machines](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1KernelMachine.html), but more on this later. To play with this interactively have a look at this: [web demo](http://demos.shogun-toolbox.org/classifier/binary/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance and Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you assess the quality of a prediction? Shogun provides various ways to do this using [CEvaluation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CEvaluation.html). The preformance is evaluated by comparing the predicted output and the expected output. Some of the base classes for performance measures are:\n",
    "\n",
    "* [Binary class evaluation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CBinaryClassEvaluation.html): used to evaluate binary classification labels. \n",
    "* [Clustering evaluation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1ClusteringEvaluation.html): used to evaluate clustering.\n",
    "* [Mean absolute error](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CMeanAbsoluteError.html): used to compute an error of regression model.\n",
    "* [Multiclass accuracy](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1MulticlassAccuracy.html): used to compute accuracy of multiclass classification. \n",
    "\n",
    "Evaluating on training data should be avoided since the learner may adjust to very specific random features of the training data which are not very important to the general relation. This is called [overfitting](http://en.wikipedia.org/wiki/Overfitting). Maximising performance on the training examples usually results in algorithms explaining the noise in data (rather than actual patterns), which leads to bad performance on unseen data. The dataset will now be split into two, we train on one part and evaluate performance on other using [CAccuracyMeasure](http://shogun-toolbox.org/api/latest/classshogun_1_1CAccuracyMeasure.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split features for training and evaluation\n",
    "num_train=700\n",
    "feats=np.array(glucose_conc)\n",
    "feats_t=feats[:num_train]\n",
    "feats_e=feats[num_train:]\n",
    "feats=np.array(BMI)\n",
    "feats_t1=feats[:num_train]\n",
    "feats_e1=feats[num_train:]\n",
    "feats_t=np.vstack((feats_t, feats_t1))\n",
    "feats_e=np.vstack((feats_e, feats_e1))\n",
    "\n",
    "feats_train = sg.create_features(feats_t)\n",
    "feats_evaluate = sg.create_features(feats_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the accuracy by applying on test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_t=trainlab[:num_train]\n",
    "labels=sg.create_labels(label_t)\n",
    "label_e=trainlab[num_train:]\n",
    "labels_true=sg.create_labels(label_e)\n",
    "\n",
    "svm=sg.create_machine(\"LibLinear\", C1=C, C2=C,\n",
    "               liblinear_solver_type=\"L2R_L2LOSS_SVC\")\n",
    "\n",
    "#train and evaluate\n",
    "svm.train(feats_train, labels)\n",
    "output=svm.apply(feats_evaluate)\n",
    "\n",
    "#use AccuracyMeasure to get accuracy\n",
    "acc=sg.create_evaluation(\"AccuracyMeasure\")\n",
    "accuracy=acc.evaluate(output,labels_true)*100\n",
    "print('Accuracy(%):', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate more efficiently [cross-validation](http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29) is used. As you might have wondered how are the parameters of the classifier selected? Shogun has a model selection framework to select the best parameters. More description of these things in [this notebook](http://shogun-toolbox.org/notebook/latest/xval_modelselection.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More predictions: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate another type of machine learning problem on real world data.</br> The task is to estimate prices of houses in Boston using the [Boston Housing Dataset](https://archive.ics.uci.edu/ml/datasets/Housing) provided by [StatLib library](http://lib.stat.cmu.edu/DASL/). The attributes are: Weighted distances to employment centres and percentage lower status of the population. Let us see if we can predict a good relationship between the pricing of houses and the attributes. This type of problems are solved using [Regression analysis](http://en.wikipedia.org/wiki/Regression_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is now loaded using [LibSVMFile](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CLibSVMFile.html) as in the previous sections and the attributes required (7th and 12th vector ) are converted to Shogun format features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_feats = sg.create_features(sg.read_csv(os.path.join(SHOGUN_DATA_DIR, 'uci/housing/fm_housing.dat')))\n",
    "labels=sg.create_labels(sg.read_csv(os.path.join(SHOGUN_DATA_DIR, 'uci/housing/housing_label.dat')))\n",
    "\n",
    "#rescale to 0...1\n",
    "preproc=sg.create_transformer(\"RescaleFeatures\")\n",
    "preproc.fit(temp_feats)\n",
    "temp_feats = preproc.transform(temp_feats)\n",
    "mat = temp_feats.get(\"feature_matrix\")\n",
    "\n",
    "dist_centres=mat[7]\n",
    "lower_pop=mat[12]\n",
    "\n",
    "feats=np.array(dist_centres)\n",
    "feats=np.vstack((feats, np.array(lower_pop)))\n",
    "print(feats, feats.shape)\n",
    "#convert to shogun format features\n",
    "feats_train = sg.create_features(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool we will use here to perform regression is [Kernel ridge regression](http://shogun-toolbox.org/doc/en/latest/classshogun_1_1KernelRidgeRegression.html). Kernel Ridge Regression is a non-parametric version of ridge regression where the [kernel trick](http://en.wikipedia.org/wiki/Kernel_trick) is used to solve a related linear ridge regression problem in a higher-dimensional space, whose results correspond to non-linear regression in the data-space.  Again we train on the data and apply on the XY grid to get predicitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "size=100\n",
    "x1=np.linspace(0, 1.0, size)\n",
    "x2=np.linspace(0, 1.0, size)\n",
    "x, y=np.meshgrid(x1, x2)\n",
    "#Generate X-Y grid test data\n",
    "grid = sg.create_features(np.array((np.ravel(x), np.ravel(y))))\n",
    "\n",
    "#Train on data(both attributes) and predict\n",
    "width=1.0\n",
    "tau=0.5\n",
    "kernel=sg.create_kernel(\"GaussianKernel\", width=width)\n",
    "krr=sg.create_machine(\"KernelRidgeRegression\",tau=tau, kernel=kernel, labels=labels)\n",
    "krr.train(feats_train)\n",
    "kernel.init(feats_train, grid)\n",
    "out = krr.apply().get(\"labels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `out` variable now contains a relationship between the attributes. Below is an attempt to establish such relationship between the attributes individually. Separate feature instances are created for each attribute. You could skip the code and have a look at the plots directly if you just want the essence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature objects for individual attributes.\n",
    "feats_test = sg.create_features(x1.reshape(1,len(x1)))\n",
    "feats_t0=np.array(dist_centres)\n",
    "feats_train0 = sg.create_features(feats_t0.reshape(1,len(feats_t0)))\n",
    "feats_t1=np.array(lower_pop)\n",
    "feats_train1 = sg.create_features(feats_t1.reshape(1,len(feats_t1)))\n",
    "\n",
    "#Regression with first attribute\n",
    "kernel=sg.create_kernel(\"GaussianKernel\", width=width)\n",
    "krr=sg.create_machine(\"KernelRidgeRegression\",tau=tau, kernel=kernel, labels=labels)\n",
    "krr.train(feats_train0)\n",
    "kernel.init(feats_train0, feats_test)\n",
    "out0 = krr.apply().get(\"labels\")\n",
    "\n",
    "#Regression with second attribute \n",
    "kernel=sg.create_kernel(\"GaussianKernel\", width=width)\n",
    "krr=sg.create_machine(\"KernelRidgeRegression\",tau=tau, kernel=kernel, labels=labels)\n",
    "krr.train(feats_train1)\n",
    "kernel.init(feats_train1, feats_test)\n",
    "out1 = krr.apply().get(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of regression\n",
    "fig=plt.figure(figsize=(20,6))\n",
    "#first plot with only one attribute\n",
    "fig.add_subplot(131)\n",
    "plt.title(\"Regression with 1st attribute\")\n",
    "_=plt.scatter(feats[0, :], labels.get(\"labels\"), cmap=\"gray\", s=20)\n",
    "_=plt.xlabel('Weighted distances to employment centres ')\n",
    "_=plt.ylabel('Median value of homes')\n",
    "\n",
    "_=plt.plot(x1,out0, linewidth=3)\n",
    "\n",
    "#second plot with only one attribute\n",
    "fig.add_subplot(132)\n",
    "plt.title(\"Regression with 2nd attribute\")\n",
    "_=plt.scatter(feats[1, :], labels.get(\"labels\"), cmap=\"gray\", s=20)\n",
    "_=plt.xlabel('% lower status of the population')\n",
    "_=plt.ylabel('Median value of homes')\n",
    "_=plt.plot(x1,out1, linewidth=3)\n",
    "\n",
    "#Both attributes and regression output\n",
    "ax=fig.add_subplot(133, projection='3d')\n",
    "z=out.reshape((size, size))\n",
    "plt.gray()\n",
    "plt.title(\"Regression\")\n",
    "ax.plot_wireframe(y, x, z, linewidths=2, alpha=0.4)\n",
    "ax.set_xlabel('% lower status of the population')\n",
    "ax.set_ylabel('Distances to employment centres ')\n",
    "ax.set_zlabel('Median value of homes')\n",
    "ax.view_init(25, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
