{
 "metadata": {
  "name": "Introduction"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Machine Learning with Shogun"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we will see how a general machine learning problem is represented and solved in shogun. As a primer to shoguns's many capabilities, we will see how various types of data and its attributes are handled and also how prediction is done. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Machine learning implies we want to to make and improve predictions or behaviors based on some data. The prediction can be of different types:    [Supervised](http://en.wikipedia.org/wiki/Supervised_learning), [Unsupervised](http://en.wikipedia.org/wiki/Unsupervised_learning), etc. Shogun provides a host of functionality to do most of these. To get off the mark, let us see how shogun handles the attributes of the data using [Features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CFeatures.html). A feature is generally an individual measurable property of some data being observed."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature representation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Shogun supports wide range of feature representations. Among these are [String features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CStringFeatures.html), [Dense features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CDenseFeatures.html), [Sparse features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CSparseFeatures.html), etc. To start with let's see how we can define some easy data using float type values."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us consider an example, instead of just abstract concepts. We have a dataset about various attributes of individuals and we know whether or not they are diabetic. Now this is a classic machine learning problem. We know the attributes for which a patient is diabetic and want to predict for other unknown values if he is diabetic. This type of learning problem falls under [Supervised learning](http://en.wikipedia.org/wiki/Supervised_learning)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will play with two attributes, Plasma glucose concentration and Body Mass Index (BMI) and try to learn something about their relationship with the disease. Now we define some random values but later we will try this on a real world dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#To import all shogun classes\n",
      "from modshogun import *\n",
      "\n",
      "#Generate some random data\n",
      "X = 2 * random.randn(20,2)\n",
      "traindata=r_[X + 5, X + 8].T\n",
      "\n",
      "print traindata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a matrix with 2 rows. These rows are our two attributes/features. Let's call it the feature matrix.</br> To convert these features in shogun format let us use `RealFeatures` which are nothing but the above mentioned [Dense features](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CDenseFeatures.html) of `64bit Float` type. To do this call `RealFeatures` with the feature matrix as the argument. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feats_train=RealFeatures(traindata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Assigning labels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to label data to be able to differentiate between them. Shogun provides various types of labels to do this through [Clabels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CLabels.html).</br> In this particular problem, our data can be of two types either diabetic or non-diabetic, so we need [binary labels](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CBinaryLabels.html). This makes it a [Binary Classification problem](http://en.wikipedia.org/wiki/Binary_classification), where we classify the data in two groups: if an individual has diabetes and does not have it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create array of labels with 1 and -1\n",
      "trainlab=concatenate((ones(20),-ones(20)))\n",
      "print trainlab\n",
      "#convert to shogun format labels\n",
      "labels=BinaryLabels(trainlab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Prediction with machines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Shogun provides tools for classification, regression, etc. through [CMachine](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CMachine.html). Basically we need to $\\it train$  the machine on some training data to be able to learn from it. Then we $\\it apply$ it to test data to get predictions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the training data\n",
      "figure(figsize=(6,4))\n",
      "gray()\n",
      "_=scatter(traindata[0, :], traindata[1,:], c=labels, s=50)\n",
      "title(\"Training Data\")\n",
      "gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can intuitively understand how the data can be separated in the plot. Now let us see if our classifer is up to the task. It is unlikely we will get such an easy separation with real data though.</br> Moving on to the prediction part, we will use [Liblinear](http://www.shogun-toolbox.org/doc/en/current/classshogun_1_1CLibLinear.html), a linear SVM, to do the classification (more on SVMs in [this notebook](http://www.shogun-toolbox.org/static/notebook/current/SupportVectorMachines.html))."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#prameters to svm\n",
      "C=0.9\n",
      "epsilon=1e-3\n",
      "\n",
      "svm=LibLinear(C, feats_train, labels)\n",
      "svm.set_liblinear_solver_type(L2R_L2LOSS_SVC)\n",
      "svm.set_epsilon(epsilon)\n",
      "\n",
      "#train\n",
      "svm.train()\n",
      "\n",
      "size=100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now `apply` on test features to get predictions. Let us use the whole XY grid as test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "x1=linspace(0, 14, size)\n",
      "x2=linspace(0, 14, size)\n",
      "x, y=meshgrid(x1, x2)\n",
      "#Generate X-Y grid test data\n",
      "grid=RealFeatures(array((ravel(x), ravel(y))))\n",
      "\n",
      "#apply on test grid\n",
      "predictions = svm.apply(grid)\n",
      "\n",
      "z=predictions.get_values().reshape((size, size))\n",
      "\n",
      "#plot\n",
      "jet()\n",
      "figure(figsize=(8,6))\n",
      "title(\"Classification\")\n",
      "c=pcolor(x, y, z)\n",
      "_=contour(x, y, z, linewidths=1, colors='black', hold=True)\n",
      "_=colorbar(c)\n",
      "\n",
      "gray()\n",
      "_=scatter(traindata[0, :], traindata[1,:], c=labels, s=50)\n",
      "gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we can see a nice boundary is predicted to classify the data and this is surely close to what our human machine reasoned!  To play with this interactively have a look at this: [web demo](http://demos.shogun-toolbox.org/classifier/binary/) "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Using datasets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Shogun provides the capability to load datasets of different formats using [CFile](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CFile.html).</br> Now we will use a real world dataset regarding the previous example:[Pima Indians Diabetes data set](http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes). We load the `LibSVM` format file using shogun's [LibSVMFile](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CLibSVMFile.html) class. Since `LibSVM` format files have labels included in the file, we get them with `load_with_labels`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f=SparseRealFeatures()\n",
      "#Load the file and generate labels.\n",
      "trainlab=f.load_with_labels(LibSVMFile('../../../data/toy/diabetes_scale.svm'))\n",
      "labels=BinaryLabels(trainlab)\n",
      "#Get the feature matrix\n",
      "mat=f.get_full_feature_matrix()\n",
      "feats=array(mat[1])\n",
      "feats=vstack((feats, array(mat[5])))\n",
      "print feats, feats.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we get hold of the feature matrix we get vectors 1 and 5 which are the attributes we are interested in: Plasma glucose concentration and Body Mass Index (BMI). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#convert to shogun format\n",
      "feats_train=RealFeatures(feats)\n",
      "#plot the training data\n",
      "figure(figsize=(6,5))\n",
      "_=scatter(feats[0, :], feats[1,:], c=trainlab, s=50)\n",
      "_=xlabel('Plasma glucose concentration')\n",
      "_=ylabel('Body mass index')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What follows next is the now familiar routine of training and applying, similar to the previous section. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "C=0.9\n",
      "epsilon=1e-3\n",
      "\n",
      "svm=LibLinear(C, feats_train, labels)\n",
      "svm.set_liblinear_solver_type(L2R_L2LOSS_SVC)\n",
      "svm.set_epsilon(epsilon)\n",
      "\n",
      "#train\n",
      "svm.train()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "size=100\n",
      "x1=linspace(-1.2, 1.2, size)\n",
      "x2=linspace(-1.2, 1.2, size)\n",
      "x, y=meshgrid(x1, x2)\n",
      "#Generate X-Y grid test data\n",
      "grid=RealFeatures(array((ravel(x), ravel(y))))\n",
      "\n",
      "#apply on test grid\n",
      "predictions = svm.apply(grid)\n",
      "\n",
      "z=predictions.get_values().reshape((size, size))\n",
      "\n",
      "#plot\n",
      "jet()\n",
      "figure(figsize=(8,6))\n",
      "title(\"Classification\")\n",
      "c=pcolor(x, y, z)\n",
      "_=contour(x, y, z, linewidths=1, colors='black', hold=True)\n",
      "_=colorbar(c)\n",
      "\n",
      "gray()\n",
      "_=scatter(feats[0, :], feats[1,:], c=trainlab, s=50)\n",
      "_=xlabel('Plasma glucose concentration')\n",
      "_=ylabel('Body mass index')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This seems like a decent enough prediction. We can thus infer that individuals below a ceratin level of BMI and glucose are most certainly safe. To have more strict boundaries explore many more of shogun's classifiers including [Kernel machines](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CKernelMachine.html), etc."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluating performance and Model selection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How do you assess the quality of a prediction? Shogun provides various ways to do this using [CEvaluation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CEvaluation.html). To keep things simple let us split the dataset, train on one part and evaluate performance on other using [ROCEvaluation](http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CROCEvaluation.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#split features for training and evaluation\n",
      "feats=array(mat[1])\n",
      "feats_t=feats[0:700]\n",
      "feats_e=feats[700:785]\n",
      "feats=array(mat[5])\n",
      "feats_t1=feats[0:700]\n",
      "feats_e1=feats[700:785]\n",
      "feats_t=vstack((feats_t, feats_t1))\n",
      "feats_e=vstack((feats_e, feats_e1))\n",
      "\n",
      "feats_train=RealFeatures(feats_t)\n",
      "feats_evaluate=RealFeatures(feats_e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see the accuracy by applying on test features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_t=trainlab[0:700]\n",
      "labels=BinaryLabels(label_t)\n",
      "label_e=trainlab[700:785]\n",
      "labels_true=BinaryLabels(label_e)\n",
      "\n",
      "svm=LibLinear(C, feats_train, labels)\n",
      "svm.set_liblinear_solver_type(L2R_L2LOSS_SVC)\n",
      "svm.set_epsilon(epsilon)\n",
      "\n",
      "#train and evaluate\n",
      "svm.train()\n",
      "output=svm.apply(feats_evaluate)\n",
      "\n",
      "#use ROCEvaluation to get accuracy\n",
      "evaluator=ROCEvaluation()\n",
      "print 'Accuracy(%):'\n",
      "print evaluator.evaluate(output,labels_true)*100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To evaluate more efficiently [cross-validation](http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29) is used. As you might have wondered how are the parameters of the classifier selected? Shogun has a model selection framework to select the best parameters. More description of these things in [this notebook](http://www.shogun-toolbox.org/static/notebook/current/xval_modelselection.html)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}