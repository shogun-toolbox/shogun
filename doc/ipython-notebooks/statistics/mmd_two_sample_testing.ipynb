{
 "metadata": {
  "name": "mmd_two_sample_testing"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Kernel two-sample testing in Shogun"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate some very basic example data in 1D.\n",
      "\n",
      "Gaussian: $p(x)=\\frac{1}{\\sqrt(2\\pi\\sigma^2)}\\exp\\left(-\\frac{(x-\\mu)^2}{\\sigma^2}\\right)$ with mean $\\mu$ and variance $\\sigma^2$\n",
      "\n",
      "Laplace: $p(x)=\\frac{1}{2b}\\exp\\left(-\\frac{|x-\\mu|}{b}\\right)$ with mean $\\mu$ and variance $2b^2$\n",
      "\n",
      "Means and variances are set to be equal"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm, laplace\n",
      "\n",
      "sigma2=1\n",
      "mu=0\n",
      "b=sqrt(0.5)\n",
      "\n",
      "Xs=linspace(-2, 2, 500)\n",
      "plot(Xs, norm.pdf(Xs, loc=mu, scale=sigma2))\n",
      "plot(Xs, laplace.pdf(Xs, loc=mu, scale=b))\n",
      "_=legend([ 'Gaussian','Laplace'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sample from these distributions and plot histogram, and compute first two moments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=220\n",
      "X=norm.rvs(size=n, loc=mu, scale=sigma2)\n",
      "Y=laplace.rvs(size=n, loc=mu, scale=b)\n",
      "\n",
      "subplot(1,2,1)\n",
      "hist(X)\n",
      "xlim([-5,5])\n",
      "ylim([0,100])\n",
      "title('Gaussian')\n",
      "subplot(1,2,2)\n",
      "title('Laplace')\n",
      "hist(Y)\n",
      "xlim([-5,5])\n",
      "_=ylim([0,100])\n",
      "\n",
      "print \"Gaussian sample mean\", mean(X)\n",
      "print \"Laplacian sample mean\", mean(Y)\n",
      "print \"Gaussian sample variance\", var(X)\n",
      "print \"Laplacian sample variance\", var(Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bring into Shogun representation and create quadratic time MMD instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shogun.Features import RealFeatures\n",
      "from shogun.Kernel import GaussianKernel, CustomKernel\n",
      "from shogun.Statistics import QuadraticTimeMMD\n",
      "from shogun.Statistics import BOOTSTRAP, UNBIASED\n",
      "\n",
      "feat_p=RealFeatures(reshape(X, (1,len(X))))\n",
      "feat_q=RealFeatures(reshape(Y, (1,len(Y))))\n",
      "kernel_width=1\n",
      "kernel=GaussianKernel(10, kernel_width)\n",
      "mmd=QuadraticTimeMMD(kernel, feat_p, feat_q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute two-sample test using permutation/bootstrapping, precompute kernel matrix for that"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# precompute kernel to be faster for null sampling\n",
      "p_and_q=mmd.get_p_and_q()\n",
      "kernel.init(p_and_q, p_and_q);\n",
      "precomputed_kernel=CustomKernel(kernel);\n",
      "mmd.set_kernel(precomputed_kernel);\n",
      "\n",
      "alpha=0.05\n",
      "mmd.set_null_approximation_method(BOOTSTRAP);\n",
      "mmd.set_bootstrap_iterations(250);\n",
      "p_value_boot=mmd.perform_test();\n",
      "\n",
      "print p_value_boot, alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualise distribution of MMD statistic under $H_0:p=q$ and $H_A:p\\neq q$. Sample both null and alternative distribution for that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_samples=250\n",
      "\n",
      "# sample null distribution\n",
      "null_samples=mmd.bootstrap_null(num_samples)\n",
      "\n",
      "# sample alternative distribution, generate new data for that\n",
      "alt_samples=zeros(num_samples)\n",
      "for i in range(num_samples):\n",
      "    X=norm.rvs(size=n, loc=mu, scale=sigma2)\n",
      "    Y=laplace.rvs(size=n, loc=mu, scale=b)\n",
      "    feat_p=RealFeatures(reshape(X, (1,len(X))))\n",
      "    feat_q=RealFeatures(reshape(Y, (1,len(Y))))\n",
      "    mmd=QuadraticTimeMMD(kernel, feat_p, feat_q)\n",
      "    alt_samples[i]=mmd.compute_statistic()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualise both distributions, $H_0:p=q$ is rejected if a sample MMD is larger than a the $(1-\\alpha)$-quantil of the null distribution. The null distribution has a very complicated form and is hard to analyse. However, there exist some more sohpisticated methods (faster than bootstrapping/permutation) that are implemented in Shogun."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subplot(1,2,1)\n",
      "hist(null_samples, color='blue')\n",
      "title('Null distribution')\n",
      "subplot(1,2,2)\n",
      "title('Alternative distribution')\n",
      "hist(alt_samples, color='green')\n",
      "\n",
      "figure()\n",
      "hist(null_samples, color='blue')\n",
      "hist(alt_samples, color='green', alpha=0.5)\n",
      "title('Null and alternative distriution')\n",
      "\n",
      "# find (1-alpha) element of null distribution\n",
      "null_samples=sort(null_samples)\n",
      "quantile=null_samples[round(num_samples*(1-alpha))]\n",
      "axvline(x=quantile, ymin=0, ymax=100, color='red', label=str(int(round((1-alpha)*100))) + '% quantile')\n",
      "_=legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So far, we basically had to precompute the kernel matrix for reasonable runtimes. This is not possible for more than a few thousand points. The linear time MMD statistic can help here. And it can do more cool things, for example choose the best single (or combined) kernel for you. But we need a more fancy dataset for that to show its power. We will use one of Shogun's streaming based data generators for that, the mmd class asks for examples one by one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from shogun.Kernel import CombinedKernel\n",
      "from shogun.Features import GaussianBlobsDataGenerator\n",
      "from shogun.Statistics import LinearTimeMMD\n",
      "from shogun.Statistics import MMDKernelSelectionOpt\n",
      "from shogun.Statistics import MMD1_GAUSSIAN\n",
      "\n",
      "m=20000\n",
      "distance=10\n",
      "stretch=5\n",
      "num_blobs=3\n",
      "angle=pi/4\n",
      "\n",
      "# these are streaming features\n",
      "gen_p=GaussianBlobsDataGenerator(num_blobs, distance, 1, 0)\n",
      "gen_q=GaussianBlobsDataGenerator(num_blobs, distance, stretch, angle)\n",
      "\t\t\n",
      "# stream some data and plot\n",
      "num_plot=1000\n",
      "features=gen_p.get_streamed_features(num_plot)\n",
      "features=features.create_merged_copy(gen_q.get_streamed_features(num_plot))\n",
      "data=features.get_feature_matrix()\n",
      "\n",
      "figure(figsize=(8,5))\n",
      "subplot(2,2,1)\n",
      "grid(True)\n",
      "plot(data[0][0:num_plot], data[1][0:num_plot], 'r.', label='$x$')\n",
      "title('$X\\sim p$')\n",
      "subplot(2,2,2)\n",
      "grid(True)\n",
      "plot(data[0][num_plot+1:2*num_plot], data[1][num_plot+1:2*num_plot], 'b.', label='$x$', alpha=0.5)\n",
      "_=title('$Y\\sim q$')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What is the best kernel to use here? This is tricky since the distinguishing characteristics are hidden at a small length-scale. Create some kernels to select the best from"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sigmas=[2**x for x in linspace(-5,5, 10)]\n",
      "print \"choosing kernel width from\", [\"{0:.2f}\".format(sigma) for sigma in sigmas]\n",
      "combined=CombinedKernel()\n",
      "for i in range(len(sigmas)):\n",
      "    combined.append_kernel(GaussianKernel(10, sigmas[i]))\n",
      "\n",
      "# mmd instance using streaming features, blocksize of 10000\n",
      "block_size=1000\n",
      "mmd=LinearTimeMMD(combined, gen_p, gen_q, m, block_size)\n",
      "\n",
      "# optmal kernel choice is possible for linear time MMD\n",
      "selection=MMDKernelSelectionOpt(mmd)\n",
      "\n",
      "# select best kernel\n",
      "kernel=selection.select_kernel()\n",
      "kernel=GaussianKernel.obtain_from_generic(kernel)\n",
      "print \"best single kernel\", kernel.get_width()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now perform two-sample test with that kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha=0.05\n",
      "mmd.set_null_approximation_method(MMD1_GAUSSIAN);\n",
      "p_value_boot=mmd.perform_test();\n",
      "\n",
      "print p_value_boot, alpha"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the linear time MMD, the null and alternative distributions look different. Let's sample them (takes longer, reduce number of samples a bit)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mmd=LinearTimeMMD(combined, gen_p, gen_q, 5000, block_size)\n",
      "num_samples=100\n",
      "\n",
      "# sample null and alternative distribution, implicitly generate new data for that\n",
      "null_samples=zeros(num_samples)\n",
      "alt_samples=zeros(num_samples)\n",
      "for i in range(num_samples):\n",
      "    alt_samples[i]=mmd.compute_statistic()\n",
      "    \n",
      "    # tell MMD to merge data internally while streaming\n",
      "    mmd.set_simulate_h0(True)\n",
      "    null_samples[i]=mmd.compute_statistic()\n",
      "    mmd.set_simulate_h0(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And visualise again. We can do kernel selection since both null and alternative distribution are Gaussian."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subplot(1,2,1)\n",
      "hist(null_samples, color='blue')\n",
      "title('Null distribution')\n",
      "subplot(1,2,2)\n",
      "title('Alternative distribution')\n",
      "hist(alt_samples, color='green')\n",
      "\n",
      "figure()\n",
      "hist(null_samples, color='blue')\n",
      "hist(alt_samples, color='green', alpha=0.5)\n",
      "title('Null and alternative distriution')\n",
      "\n",
      "# find (1-alpha) element of null distribution\n",
      "null_samples=sort(null_samples)\n",
      "quantile=null_samples[round(num_samples*(1-alpha))]\n",
      "axvline(x=quantile, ymin=0, ymax=100, color='red', label=str(int(round((1-alpha)*100))) + '% quantile')\n",
      "_=legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}