{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multi-Label Classification Using Factor Graph Model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Jiaolong Xu (Github ID: [Jiaolong](https://github.com/Jiaolong))"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This example illustrates how to use factor graph model and structured support vector machines to do multi-label classification.\n",
      "\n",
      "Multi-label classification bears similarity to multi-class classification except classes are not mutually exclusive [2]. In this example, we model label dependencies in a shallow tree structure. We compare independent predictions, i.e., using only unary factors and tree-structured interactions with respect to run-time and accuracy. Following [3], we compute Chow-Liu tree for the tree-structured model. The \u201cscene\u201d dataset is used in the experiment."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiment"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load scene dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "    \n",
      "#Load the scene multi-label dataset.\n",
      "data_file = open('../../../data/multilabel/scene.pickle', 'rb')\n",
      "scene = cPickle.load(data_file)\n",
      "\n",
      "X_train, Y_train, X_test, Y_test = scene['X_train'], scene['y_train'], scene['X_test'], scene['y_test']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "# Save dataset into plain txt file\n",
      "data_train = np.concatenate((Y_train[:10,], X_train[:10,:5]), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savetxt('scene_train.txt', data_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build label tree structure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import sparse\n",
      "\n",
      "from sklearn.metrics import hamming_loss\n",
      "from sklearn.datasets import fetch_mldata\n",
      "from sklearn.metrics import mutual_info_score\n",
      "try:\n",
      "    from sklearn.utils import minimum_spanning_tree\n",
      "except ImportError:\n",
      "    raise ImportError(\"Please install a recent version of scikit-learn or\"\n",
      "                      \"scipy to build minimum spanning trees.\")\n",
      "    \n",
      "def chow_liu_tree(y_):\n",
      "    # compute mutual information using sklearn\n",
      "    n_labels = y_.shape[1]\n",
      "    mi = np.zeros((n_labels, n_labels))\n",
      "    for i in xrange(n_labels):\n",
      "        for j in xrange(n_labels):\n",
      "            mi[i, j] = mutual_info_score(y_[:, i], y_[:, j])\n",
      "    mst = minimum_spanning_tree(sparse.csr_matrix(-mi))\n",
      "    edges = np.vstack(mst.nonzero()).T\n",
      "    edges.sort(axis=1)\n",
      "    return edges"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree = chow_liu_tree(Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Build factor graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use few data to save computation time\n",
      "num_train = 100\n",
      "num_test = 50\n",
      "X_train = X_train[:num_train,:]\n",
      "Y_train = Y_train[:num_train,:]\n",
      "X_test = X_test[:num_test,:]\n",
      "Y_test = Y_test[:num_test,:]\n",
      "\n",
      "# feature dimension\n",
      "n_tr_samples = X_train.shape[0]\n",
      "n_ts_samples = X_test.shape[0]\n",
      "n_dims = X_train.shape[1]\n",
      "# number of states {0, 1}\n",
      "n_stats = 2\n",
      "# number of classes\n",
      "n_classes = Y_test.shape[1]\n",
      "# number of edges in the tree structure\n",
      "n_edges = tree.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import TableFactorType\n",
      "\n",
      "# unary\n",
      "list_ftp_u = []\n",
      "for u in xrange(n_classes):\n",
      "    type_id = u\n",
      "    cards_u = np.array([n_stats], np.int32)\n",
      "    w_gt_u = np.zeros(n_stats*n_dims)\n",
      "    list_ftp_u.append(TableFactorType(u, cards_u, w_gt_u))\n",
      "    \n",
      "# tree structures\n",
      "list_ftp_t = []\n",
      "for t in xrange(n_edges):\n",
      "    cards_t = np.array([n_stats, n_stats], np.int32)\n",
      "    w_gt_t = np.zeros(n_stats*n_stats)\n",
      "    list_ftp_t.append(TableFactorType(u+t, cards_t, w_gt_t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_data_unary(x, y, l_ftp_u, num_samples):\n",
      "    \"\"\"prepare FactorGraphFeatures and FactorGraphLabels for unary potential\"\"\"\n",
      "    from modshogun import Factor, TableFactorType, FactorGraph\n",
      "    from modshogun import FactorGraphObservation, FactorGraphLabels, FactorGraphFeatures\n",
      "\n",
      "    samples = FactorGraphFeatures(num_samples)\n",
      "    labels = FactorGraphLabels(num_samples)\n",
      "    \n",
      "    for i in xrange(num_samples):\n",
      "        n_class = y.shape[1] # 6 labels\n",
      "        data = x[i].astype(np.float64)\n",
      "        vc = np.array([n_stats]*n_class, np.int32)\n",
      "        fg = FactorGraph(vc)\n",
      "\n",
      "        # add unary factors\n",
      "        for v in xrange(n_class):\n",
      "            datau = data\n",
      "            vindu = np.array([v], np.int32)\n",
      "            facu = Factor(l_ftp_u[v], vindu, datau)\n",
      "            fg.add_factor(facu)\n",
      "            \n",
      "        # add corresponding label\n",
      "        states_gt = y[i].astype(np.int32)\n",
      "        loss_weights = np.array([1.0/n_class]*n_class)\n",
      "        fg_obs = FactorGraphObservation(states_gt, loss_weights)\n",
      "        labels.add_label(fg_obs)\n",
      "        \n",
      "    return samples, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_data_tree(x, y, l_ftp_u, l_ftp_t, num_samples, tree):\n",
      "    \"\"\"prepare FactorGraphFeatures and FactorGraphLabels for tree tructure\"\"\"\n",
      "    from modshogun import Factor, TableFactorType, FactorGraph\n",
      "    from modshogun import FactorGraphObservation, FactorGraphLabels, FactorGraphFeatures\n",
      "\n",
      "    samples = FactorGraphFeatures(num_samples)\n",
      "    labels = FactorGraphLabels(num_samples)\n",
      "    \n",
      "    for i in xrange(num_samples):\n",
      "        n_class = y.shape[1]\n",
      "        data = x[i].astype(np.float64)\n",
      "        vc = np.array([n_stats]*n_class, np.int32)\n",
      "        fg = FactorGraph(vc)\n",
      "\n",
      "        # add unary factors\n",
      "        for u in xrange(n_class):\n",
      "            datau = data\n",
      "            vindu = np.array([u], np.int32)\n",
      "            facu = Factor(l_ftp_u[u], vindu, datau)\n",
      "            fg.add_factor(facu)\n",
      "            \n",
      "        # add tree-structure factors\n",
      "        for t in xrange(tree.shape[0]):\n",
      "            v1 = tree[t,0]\n",
      "            v2 = tree[t,1]\n",
      "            datap = np.array([1.0])\n",
      "            vindp = np.array([v1, v2], np.int32)\n",
      "            facp = Factor(l_ftp_t[t], vindp, datap)\n",
      "            fg.add_factor(facp)\n",
      "            \n",
      "        # add corresponding label\n",
      "        states_gt = y[i].astype(np.int32)\n",
      "        loss_weights = np.array([1.0/n_class]*n_class)\n",
      "        fg_obs = FactorGraphObservation(states_gt, loss_weights)\n",
      "        labels.add_label(fg_obs)\n",
      "        \n",
      "    return samples, labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# define structure\n",
      "USE_TREE_STRUCTURE = True\n",
      "if USE_TREE_STRUCTURE:\n",
      "    # prepare training pairs (factor graph, node states)\n",
      "    samples, labels = prepare_data_tree(X_train, Y_train, list_ftp_u, list_ftp_t, n_tr_samples, tree)\n",
      "else:\n",
      "    # use unary factors only\n",
      "    samples, labels = prepare_data_unary(X_train, Y_train, list_ftp_u, n_tr_samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import FactorGraphModel, TREE_MAX_PROD\n",
      "\n",
      "# create model and register factor types\n",
      "model = FactorGraphModel(samples, labels, TREE_MAX_PROD)\n",
      "for u in xrange(n_classes):\n",
      "    model.add_factor_type(list_ftp_u[0])\n",
      "if USE_TREE_STRUCTURE:\n",
      "    for t in xrange(n_edges):\n",
      "        model.add_factor_type(list_ftp_t[t])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import StochasticSOSVM\n",
      "import time\n",
      "# the 3rd parameter is do_weighted_averaging, by turning this on, \n",
      "# a possibly faster convergence rate may be achieved.\n",
      "# the 4th parameter controls outputs of verbose training information\n",
      "sgd = StochasticSOSVM(model, labels, True, True)\n",
      "\n",
      "sgd.set_num_iter(100)\n",
      "sgd.set_lambda(0.01)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "sgd.train()\n",
      "t1 = time.time()\n",
      "    \n",
      "w_sgd = sgd.get_w()\n",
      "    \n",
      "print \"SGD took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get testing data\n",
      "if USE_TREE_STRUCTURE:\n",
      "    samples_ts, labels_ts = prepare_data_tree(p_ts, l_ts, ftype_all, n_ts_samples, tree)\n",
      "else:\n",
      "    samples_ts, labels_ts = prepare_data_unary(p_ts, l_ts, ftype_all, n_ts_samples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import LabelsFactory, SOSVMHelper\n",
      "\n",
      "## training error of stochastic method\n",
      "print('SGD: Average training error is %.4f' % SOSVMHelper.average_loss(w_sgd, model))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing error of stochastic method\n",
      "print('SGD: Average training error is %.4f' % SOSVMHelper.average_loss(sgd.get_w(), model))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[1] http://www.shogun-toolbox.org/static/notebook/current/FGM.html\n",
      "\n",
      "[2] http://www.cs.cornell.edu/people/tj/publications/finley_joachims_08a.pdf\n",
      "\n",
      "[3] https://github.com/pystruct/pystruct/blob/master/examples/multi_label.py"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}